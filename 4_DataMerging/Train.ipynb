{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import os\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set paths\n",
    "dataset_dir = 'data' # Directory \n",
    "path_ama = dataset_dir + os.sep + 'amazon_products.csv'  # Amazon dataset\n",
    "path_egg = dataset_dir + os.sep + \"newegg_products.csv\"  # NewEggs dataset\n",
    "path_block = dataset_dir + os.sep + 'blocked_pairs.csv' # Labeled (G) sample after blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data with utf-8 encoding\n",
    "# Amazon\n",
    "tb_ama = em.read_csv_metadata(path_ama, key=\"ASIN\", encoding='utf-8')\n",
    "# NewEgg\n",
    "tb_egg = em.read_csv_metadata(path_egg, key=\"NID\", encoding='utf-8')\n",
    "# Sample S\n",
    "tb_block = em.read_csv_metadata(path_block, \n",
    "                        key=\"_id\", \n",
    "                        ltable=tb_ama, rtable=tb_egg, \n",
    "                        fk_ltable=\"ltable_ASIN\", fk_rtable=\"rtable_NID\", \n",
    "                        encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Upate attribute type of 'PRICE' from string to numeric\n",
    "atypes1 = em.get_attr_types(tb_ama)\n",
    "atypes1['PRICE'] = 'numeric'\n",
    "atypes2 = em.get_attr_types(tb_egg)\n",
    "atypes2['PRICE'] = 'numeric'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Features Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Feature table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate features automatically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0)\n",
    "# Random Forest\n",
    "rf = em.RFMatcher(name='RandomForest', random_state=0)\n",
    "# SVM\n",
    "svm = em.SVMMatcher(name='SVM', random_state=0)\n",
    "# Naive Bayes\n",
    "nb = em.NBMatcher(name='NaiveBayes')\n",
    "# Logistic Regression\n",
    "lg = em.LogRegMatcher(name='LogisticRegression', random_state=0)\n",
    "# LinearRegression\n",
    "ln = em.LinRegMatcher(name='LinearRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def price_small(ltuple, rtuple):\n",
    "    d = abs(float(ltuple.PRICE) - float(rtuple.PRICE))\n",
    "    if d < 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def price_exact(ltuple, rtuple):\n",
    "    d = abs(float(ltuple.PRICE) - float(rtuple.PRICE))\n",
    "    if d < 0.01:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def price_large(ltuple, rtuple):\n",
    "    d = abs(float(ltuple.PRICE) - float(rtuple.PRICE))\n",
    "    if d > 10:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def model_in_name(ltuple, rtuple):\n",
    "    lst1 = ltuple.INFO.split(' ');\n",
    "    lst2 = ltuple.NAME.split(' ');\n",
    "    if (rtuple.INFO in lst1) or (rtuple.INFO in lst2):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def refurbished(ltuple, rtuple):\n",
    "    l = 'refurbished' in ltuple.NAME.lower() \n",
    "    r = 'refurbished' in rtuple.NAME.lower() \n",
    "    if l != r:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reuse automatic features of Name\n",
    "block_c = em.get_attr_corres(tb_ama, tb_egg) # block corres\n",
    "block_c['corres'] = [('NAME', 'NAME')]\n",
    "sim = em.get_sim_funs_for_matching() # similarity functions\n",
    "tok = em.get_tokenizers_for_matching() # tokenizing functions\n",
    "F2 = em.get_features(tb_ama, tb_egg, atypes1, atypes2, block_c, tok, sim)\n",
    "\n",
    "# Brand feature\n",
    "BRAND_BRAND_lev_sim = 'lev_sim(ltuple.BRAND, rtuple.BRAND)'\n",
    "feature = em.get_feature_fn(BRAND_BRAND_lev_sim, sim, tok)\n",
    "em.add_feature(F2, 'BRAND_BRAND_lev_sim', feature)\n",
    "\n",
    "# Category feature\n",
    "CATEGORY_CATEGORY_lev_sim = 'lev_sim(ltuple.CATEGORY, rtuple.CATEGORY)'\n",
    "feature = em.get_feature_fn(CATEGORY_CATEGORY_lev_sim, sim, tok)\n",
    "em.add_feature(F2, 'CATEGORY_CATEGORY_lev_sim', feature)\n",
    "\n",
    "# Price features\n",
    "em.add_blackbox_feature(F2, 'PRICE_PRICE_exact', price_exact)\n",
    "em.add_blackbox_feature(F2, 'PRICE_PRICE_small', price_small)\n",
    "em.add_blackbox_feature(F2, 'PRICE_PRICE_large', price_large)\n",
    "\n",
    "# Info and name features\n",
    "em.add_blackbox_feature(F2, 'INFONAME_INFO_contain', model_in_name)\n",
    "em.add_blackbox_feature(F2, 'NAME_NAME_refurbished', refurbished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i_vectors2 = em.extract_feature_vecs(I, \n",
    "                                    feature_table=F2, \n",
    "                                    attrs_after='label', show_progress=False)\n",
    "i_vectors2 = em.impute_table(i_vectors2, \n",
    "                            exclude_attrs=['_id', 'ltable_ASIN', 'rtable_NID', 'label'], \n",
    "                            strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_features = F2\n",
    "best_vectors = i_vectors2\n",
    "best_model = svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# General Evaluation function\n",
    "def evaluate(model, train, test):\n",
    "    # Train on train set\n",
    "    model.fit(table=train, exclude_attrs=['_id', 'ltable_ASIN', 'rtable_NID', 'label'],\n",
    "        target_attr='label')\n",
    "    # Predict on test set\n",
    "    predictions = model.predict(table=test, exclude_attrs=['_id', 'ltable_ASIN', 'rtable_NID', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "    # Evaluate \n",
    "    eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "    # Print out\n",
    "    em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Evalution result for all 6 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. DecisionTree\n",
      "Precision : 92.21% (71/77)\n",
      "Recall : 81.61% (71/87)\n",
      "F1 : 86.59%\n",
      "False positives : 6 (out of 77 positive predictions)\n",
      "False negatives : 16 (out of 173 negative predictions)\n",
      "\n",
      "2. RandomForest\n",
      "Precision : 89.16% (74/83)\n",
      "Recall : 85.06% (74/87)\n",
      "F1 : 87.06%\n",
      "False positives : 9 (out of 83 positive predictions)\n",
      "False negatives : 13 (out of 167 negative predictions)\n",
      "\n",
      "3. SVM\n",
      "Precision : 95.65% (66/69)\n",
      "Recall : 75.86% (66/87)\n",
      "F1 : 84.62%\n",
      "False positives : 3 (out of 69 positive predictions)\n",
      "False negatives : 21 (out of 181 negative predictions)\n",
      "\n",
      "4. NaiveBayes\n",
      "Precision : 33.74% (83/246)\n",
      "Recall : 95.4% (83/87)\n",
      "F1 : 49.85%\n",
      "False positives : 163 (out of 246 positive predictions)\n",
      "False negatives : 4 (out of 4 negative predictions)\n",
      "\n",
      "5. LogisticRegression\n",
      "Precision : 95.65% (66/69)\n",
      "Recall : 75.86% (66/87)\n",
      "F1 : 84.62%\n",
      "False positives : 3 (out of 69 positive predictions)\n",
      "False negatives : 21 (out of 181 negative predictions)\n",
      "\n",
      "6. LinearRegression\n",
      "Precision : 95.65% (66/69)\n",
      "Recall : 75.86% (66/87)\n",
      "F1 : 84.62%\n",
      "False positives : 3 (out of 69 positive predictions)\n",
      "False negatives : 21 (out of 181 negative predictions)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "count = 0\n",
    "for model in [dt, rf, svm, nb, lg, ln]:\n",
    "    count += 1\n",
    "    print(str(count) + \". \" + model.name)\n",
    "    evaluate(model, best_vectors, j_vectors)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Evaluation on the best matcher - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 95.65% (66/69)\n",
      "Recall : 75.86% (66/87)\n",
      "F1 : 84.62%\n",
      "False positives : 3 (out of 69 positive predictions)\n",
      "False negatives : 21 (out of 181 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "evaluate(best_model, best_vectors, j_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 6.514814\n"
     ]
    }
   ],
   "source": [
    "# End time\n",
    "toc0 = time.clock()\n",
    "print(\"Total time: \" + str(toc0 - tic0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

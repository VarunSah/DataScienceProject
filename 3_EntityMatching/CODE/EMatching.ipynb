{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import os\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start time\n",
    "tic0 = time.clock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set paths\n",
    "dataset_dir = 'data' # Directory \n",
    "path_ama = dataset_dir + os.sep + 'amazon_products.csv'  # Amazon dataset\n",
    "path_egg = dataset_dir + os.sep + \"newegg_products.csv\"  # NewEggs dataset\n",
    "path_labeled_data = dataset_dir + os.sep + 'labeled.csv' # Labeled (G) sample after blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"py_entitymatching.io.parsers\"\n"
     ]
    }
   ],
   "source": [
    "# Load data with utf-8 encoding\n",
    "# Amazon\n",
    "tb_ama = em.read_csv_metadata(path_ama, key=\"ASIN\", encoding='utf-8')\n",
    "# NewEgg\n",
    "tb_egg = em.read_csv_metadata(path_egg, key=\"NID\", encoding='utf-8')\n",
    "# Sample S\n",
    "S = em.read_csv_metadata(path_labeled_data, \n",
    "                        key=\"_id\", \n",
    "                        ltable=tb_ama, rtable=tb_egg, \n",
    "                        fk_ltable=\"ltable_ASIN\", fk_rtable=\"rtable_NID\", \n",
    "                        encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Divide dataset into I and J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IJ = em.split_train_test(S, train_proportion=0.5, random_state=0)\n",
    "I = IJ['train']\n",
    "J = IJ['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Features Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Feature table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate features automatically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use automatic feature generator\n",
    "F = em.get_features_for_matching(tb_ama, tb_egg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 NAME_NAME_jac_qgm_3_qgm_3\n",
       "1             NAME_NAME_cos_dlm_dc0_dlm_dc0\n",
       "2         CATEGORY_CATEGORY_jac_qgm_3_qgm_3\n",
       "3     CATEGORY_CATEGORY_cos_dlm_dc0_dlm_dc0\n",
       "4     CATEGORY_CATEGORY_jac_dlm_dc0_dlm_dc0\n",
       "5                     CATEGORY_CATEGORY_mel\n",
       "6                CATEGORY_CATEGORY_lev_dist\n",
       "7                 CATEGORY_CATEGORY_lev_sim\n",
       "8                     CATEGORY_CATEGORY_nmw\n",
       "9                      CATEGORY_CATEGORY_sw\n",
       "10              NUM_REVIEWS_NUM_REVIEWS_exm\n",
       "11              NUM_REVIEWS_NUM_REVIEWS_anm\n",
       "12         NUM_REVIEWS_NUM_REVIEWS_lev_dist\n",
       "13          NUM_REVIEWS_NUM_REVIEWS_lev_sim\n",
       "14              BRAND_BRAND_jac_qgm_3_qgm_3\n",
       "15          BRAND_BRAND_cos_dlm_dc0_dlm_dc0\n",
       "16          BRAND_BRAND_jac_dlm_dc0_dlm_dc0\n",
       "17                          BRAND_BRAND_mel\n",
       "18                     BRAND_BRAND_lev_dist\n",
       "19                      BRAND_BRAND_lev_sim\n",
       "20                          BRAND_BRAND_nmw\n",
       "21                           BRAND_BRAND_sw\n",
       "Name: feature_name, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.feature_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Extract feature vectors from set I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i_vectors = em.extract_feature_vecs(I, \n",
    "                                    feature_table=F, \n",
    "                                    attrs_after='label', show_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "any(pd.notnull(i_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filling missing by median\n",
    "i_vectors = em.impute_table(i_vectors, \n",
    "                            exclude_attrs=['_id', 'ltable_ASIN', 'rtable_NID', 'label'], \n",
    "                            strategy='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Matcher Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Initialize matchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0)\n",
    "# Random Forest\n",
    "rf = em.RFMatcher(name='RandomForest', random_state=0)\n",
    "# SVM\n",
    "svm = em.SVMMatcher(name='SVM', random_state=0)\n",
    "# Naive Bayes\n",
    "nb = em.NBMatcher(name='NaiveBayes')\n",
    "# Logistic Regression\n",
    "lg = em.LogRegMatcher(name='LogisticRegression', random_state=0)\n",
    "# LinearRegression\n",
    "ln = em.LinRegMatcher(name='LinearRegression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Cross validation on I set (1st time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cv(vectors):\n",
    "    for m in ['precision', 'recall', 'f1']:\n",
    "        print('\\n' + m)\n",
    "        result = em.select_matcher([dt, rf, svm, nb, lg, ln], \n",
    "                                   table=vectors, \n",
    "                                   exclude_attrs=['_id', 'ltable_ASIN', 'rtable_NID', 'label'],\n",
    "                                   k=5, \n",
    "                                   target_attr='label', \n",
    "                                   metric=m,\n",
    "                                   random_state=0)\n",
    "    #     display(result['cv_stats'])\n",
    "        alist = result['cv_stats']['Name']\n",
    "        blist = result['cv_stats']['Mean score']\n",
    "        for i, (a, b) in enumerate(zip(alist, blist)):\n",
    "            print(str(i) + \". \" + str(a) + \"\\t\" + str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision\n",
      "0. DecisionTree\t0.705211558308\n",
      "1. RandomForest\t0.767395104895\n",
      "2. SVM\t0.723869463869\n",
      "3. NaiveBayes\t0.615305242664\n",
      "4. LogisticRegression\t0.555649350649\n",
      "5. LinearRegression\t0.718095238095\n",
      "\n",
      "recall\n",
      "0. DecisionTree\t0.78099219621\n",
      "1. RandomForest\t0.663623188406\n",
      "2. SVM\t0.523366778149\n",
      "3. NaiveBayes\t0.753021181717\n",
      "4. LogisticRegression\t0.229096989967\n",
      "5. LinearRegression\t0.315785953177\n",
      "\n",
      "f1\n",
      "0. DecisionTree\t0.723386394307\n",
      "1. RandomForest\t0.69230020284\n",
      "2. SVM\t0.597563726596\n",
      "3. NaiveBayes\t0.637416463295\n",
      "4. LogisticRegression\t0.315084029486\n",
      "5. LinearRegression\t0.415632183908\n"
     ]
    }
   ],
   "source": [
    "cv(i_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Debug (on Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random forest\n",
    "PQ = em.split_train_test(i_vectors, train_proportion=0.5, random_state=0)\n",
    "P = PQ['train']\n",
    "Q = PQ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Debug RF matcher using GUI\n",
    "# em.vis_debug_rf(rf, P, Q, \n",
    "#         exclude_attrs=['_id', 'ltable_ASIN', 'rtable_NID', 'label'],\n",
    "#         target_attr='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Upate attribute type of 'PRICE' from string to numeric\n",
    "atypes1 = em.get_attr_types(tb_ama)\n",
    "atypes1['PRICE'] = 'numeric'\n",
    "atypes2 = em.get_attr_types(tb_egg)\n",
    "atypes2['PRICE'] = 'numeric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "block_c = em.get_attr_corres(tb_ama, tb_egg) # block corres\n",
    "sim = em.get_sim_funs_for_matching() # similarity functions\n",
    "tok = em.get_tokenizers_for_matching() # tokenizing functions\n",
    "# matching features\n",
    "F1 = em.get_features(tb_ama, tb_egg, \n",
    "                    atypes1, atypes2, \n",
    "                    block_c, tok, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def price_small(ltuple, rtuple):\n",
    "    d = abs(float(ltuple.PRICE) - float(rtuple.PRICE))\n",
    "    if d < 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em.add_blackbox_feature(F1, 'PRICE_PRICE_small', price_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/python2/lib/python2.7/site-packages/py_entitymatching/feature/simfunctions.py:713: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if d1 == d2:\n"
     ]
    }
   ],
   "source": [
    "i_vectors1 = em.extract_feature_vecs(I, \n",
    "                                    feature_table=F1, \n",
    "                                    attrs_after='label', show_progress=False)\n",
    "i_vectors1 = em.impute_table(i_vectors1, \n",
    "                            exclude_attrs=['_id', 'ltable_ASIN', 'rtable_NID', 'label'], \n",
    "                            strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision\n",
      "0. DecisionTree\t0.697130004498\n",
      "1. RandomForest\t0.8\n",
      "2. SVM\t0.687459207459\n",
      "3. NaiveBayes\t0.601158536585\n",
      "4. LogisticRegression\t0.54683982684\n",
      "5. LinearRegression\t0.631666666667\n",
      "\n",
      "recall\n",
      "0. DecisionTree\t0.664347826087\n",
      "1. RandomForest\t0.622296544036\n",
      "2. SVM\t0.532062430323\n",
      "3. NaiveBayes\t0.788361204013\n",
      "4. LogisticRegression\t0.20762541806\n",
      "5. LinearRegression\t0.393946488294\n",
      "\n",
      "f1\n",
      "0. DecisionTree\t0.660907645458\n",
      "1. RandomForest\t0.687476190476\n",
      "2. SVM\t0.587254480287\n",
      "3. NaiveBayes\t0.652499134077\n",
      "4. LogisticRegression\t0.283238866397\n",
      "5. LinearRegression\t0.470443722944\n"
     ]
    }
   ],
   "source": [
    "cv(i_vectors1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def price_exact(ltuple, rtuple):\n",
    "    d = abs(float(ltuple.PRICE) - float(rtuple.PRICE))\n",
    "    if d < 0.01:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def price_large(ltuple, rtuple):\n",
    "    d = abs(float(ltuple.PRICE) - float(rtuple.PRICE))\n",
    "    if d > 10:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_c['corres'] = [('NAME', 'NAME')]\n",
    "F2 = em.get_features(tb_ama, tb_egg, atypes1, atypes2, block_c, tok, sim)\n",
    "em.add_blackbox_feature(F2, 'PRICE_PRICE_exact', price_exact)\n",
    "em.add_blackbox_feature(F2, 'PRICE_PRICE_small', price_small)\n",
    "em.add_blackbox_feature(F2, 'PRICE_PRICE_large', price_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_vectors2 = em.extract_feature_vecs(I, \n",
    "                                    feature_table=F2, \n",
    "                                    attrs_after='label', show_progress=False)\n",
    "i_vectors2 = em.impute_table(i_vectors2, \n",
    "                            exclude_attrs=['_id', 'ltable_ASIN', 'rtable_NID', 'label'], \n",
    "                            strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision\n",
      "0. DecisionTree\t0.725386996904\n",
      "1. RandomForest\t0.796478375426\n",
      "2. SVM\t0.590649350649\n",
      "3. NaiveBayes\t0.391692307692\n",
      "4. LogisticRegression\t0.59\n",
      "5. LinearRegression\t0.658095238095\n",
      "\n",
      "recall\n",
      "0. DecisionTree\t0.775774804905\n",
      "1. RandomForest\t0.773745819398\n",
      "2. SVM\t0.32508361204\n",
      "3. NaiveBayes\t0.916666666667\n",
      "4. LogisticRegression\t0.255596432553\n",
      "5. LinearRegression\t0.411917502787\n",
      "\n",
      "f1\n",
      "0. DecisionTree\t0.737316948285\n",
      "1. RandomForest\t0.77382847038\n",
      "2. SVM\t0.372794485455\n",
      "3. NaiveBayes\t0.527160486393\n",
      "4. LogisticRegression\t0.32294453305\n",
      "5. LinearRegression\t0.487009222661\n"
     ]
    }
   ],
   "source": [
    "cv(i_vectors2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_in_name(ltuple, rtuple):\n",
    "    lst1 = ltuple.INFO.split(' ');\n",
    "    lst2 = ltuple.NAME.split(' ');\n",
    "    if (rtuple.INFO in lst1) or (rtuple.INFO in lst2):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def refurbished(ltuple, rtuple):\n",
    "    l = 'refurbished' in ltuple.NAME.lower() \n",
    "    r = 'refurbished' in rtuple.NAME.lower() \n",
    "    if l != r:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reuse automatic features of Name\n",
    "block_c['corres'] = [('NAME', 'NAME')]\n",
    "\n",
    "F3 = em.get_features(tb_ama, tb_egg, atypes1, atypes2, block_c, tok, sim)\n",
    "\n",
    "# Brand feature\n",
    "BRAND_BRAND_lev_sim = 'lev_sim(ltuple.BRAND, rtuple.BRAND)'\n",
    "feature = em.get_feature_fn(BRAND_BRAND_lev_sim, sim, tok)\n",
    "em.add_feature(F3, 'BRAND_BRAND_lev_sim', feature)\n",
    "\n",
    "# Category feature\n",
    "CATEGORY_CATEGORY_lev_sim = 'lev_sim(ltuple.CATEGORY, rtuple.CATEGORY)'\n",
    "feature = em.get_feature_fn(CATEGORY_CATEGORY_lev_sim, sim, tok)\n",
    "em.add_feature(F3, 'CATEGORY_CATEGORY_lev_sim', feature)\n",
    "\n",
    "# Price features\n",
    "em.add_blackbox_feature(F3, 'PRICE_PRICE_exact', price_exact)\n",
    "em.add_blackbox_feature(F3, 'PRICE_PRICE_small', price_small)\n",
    "em.add_blackbox_feature(F3, 'PRICE_PRICE_large', price_large)\n",
    "\n",
    "# Info and name features\n",
    "em.add_blackbox_feature(F3, 'INFONAME_INFO_contain', model_in_name)\n",
    "em.add_blackbox_feature(F3, 'NAME_NAME_refurbished', refurbished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i_vectors3 = em.extract_feature_vecs(I, \n",
    "                                    feature_table=F3, \n",
    "                                    attrs_after='label', show_progress=False)\n",
    "i_vectors3 = em.impute_table(i_vectors3, \n",
    "                            exclude_attrs=['_id', 'ltable_ASIN', 'rtable_NID', 'label'], \n",
    "                            strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision\n",
      "0. DecisionTree\t0.851282051282\n",
      "1. RandomForest\t0.868452380952\n",
      "2. SVM\t0.97032967033\n",
      "3. NaiveBayes\t0.398285714286\n",
      "4. LogisticRegression\t0.97032967033\n",
      "5. LinearRegression\t0.97032967033\n",
      "\n",
      "recall\n",
      "0. DecisionTree\t0.861884057971\n",
      "1. RandomForest\t0.850579710145\n",
      "2. SVM\t0.747079152731\n",
      "3. NaiveBayes\t0.933333333333\n",
      "4. LogisticRegression\t0.747079152731\n",
      "5. LinearRegression\t0.747079152731\n",
      "\n",
      "f1\n",
      "0. DecisionTree\t0.849029138503\n",
      "1. RandomForest\t0.854742830605\n",
      "2. SVM\t0.840472312002\n",
      "3. NaiveBayes\t0.53823740947\n",
      "4. LogisticRegression\t0.840472312002\n",
      "5. LinearRegression\t0.840472312002\n"
     ]
    }
   ],
   "source": [
    "cv(i_vectors3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: the best matcher is SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_features = F3\n",
    "best_vectors = i_vectors3\n",
    "best_model = svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Extract Feature vectors from J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate test feature vectors\n",
    "j_vectors = em.extract_feature_vecs(J, \n",
    "                                    feature_table=best_features, \n",
    "                                    attrs_after='label', show_progress=False)\n",
    "# Impute missing values \n",
    "j_vectors = em.impute_table(j_vectors, \n",
    "                            exclude_attrs=['_id', 'ltable_ASIN', 'rtable_NID', 'label'], \n",
    "                            strategy='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test on J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General Evaluation function\n",
    "def evaluate(model, train, test):\n",
    "    # Train on train set\n",
    "    model.fit(table=train, exclude_attrs=['_id', 'ltable_ASIN', 'rtable_NID', 'label'],\n",
    "        target_attr='label')\n",
    "    # Predict on test set\n",
    "    predictions = model.predict(table=test, exclude_attrs=['_id', 'ltable_ASIN', 'rtable_NID', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "    # Evaluate \n",
    "    eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "    # Print out\n",
    "    em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Evalution result for all 6 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. DecisionTree\n",
      "Precision : 92.21% (71/77)\n",
      "Recall : 81.61% (71/87)\n",
      "F1 : 86.59%\n",
      "False positives : 6 (out of 77 positive predictions)\n",
      "False negatives : 16 (out of 173 negative predictions)\n",
      "\n",
      "2. RandomForest\n",
      "Precision : 89.16% (74/83)\n",
      "Recall : 85.06% (74/87)\n",
      "F1 : 87.06%\n",
      "False positives : 9 (out of 83 positive predictions)\n",
      "False negatives : 13 (out of 167 negative predictions)\n",
      "\n",
      "3. SVM\n",
      "Precision : 95.65% (66/69)\n",
      "Recall : 75.86% (66/87)\n",
      "F1 : 84.62%\n",
      "False positives : 3 (out of 69 positive predictions)\n",
      "False negatives : 21 (out of 181 negative predictions)\n",
      "\n",
      "4. NaiveBayes\n",
      "Precision : 33.74% (83/246)\n",
      "Recall : 95.4% (83/87)\n",
      "F1 : 49.85%\n",
      "False positives : 163 (out of 246 positive predictions)\n",
      "False negatives : 4 (out of 4 negative predictions)\n",
      "\n",
      "5. LogisticRegression\n",
      "Precision : 95.65% (66/69)\n",
      "Recall : 75.86% (66/87)\n",
      "F1 : 84.62%\n",
      "False positives : 3 (out of 69 positive predictions)\n",
      "False negatives : 21 (out of 181 negative predictions)\n",
      "\n",
      "6. LinearRegression\n",
      "Precision : 95.65% (66/69)\n",
      "Recall : 75.86% (66/87)\n",
      "F1 : 84.62%\n",
      "False positives : 3 (out of 69 positive predictions)\n",
      "False negatives : 21 (out of 181 negative predictions)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "count = 0\n",
    "for model in [dt, rf, svm, nb, lg, ln]:\n",
    "    count += 1\n",
    "    print(str(count) + \". \" + model.name)\n",
    "    evaluate(model, best_vectors, j_vectors)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Evaluation on the best matcher - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 95.65% (66/69)\n",
      "Recall : 75.86% (66/87)\n",
      "F1 : 84.62%\n",
      "False positives : 3 (out of 69 positive predictions)\n",
      "False negatives : 21 (out of 181 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "evaluate(best_model, best_vectors, j_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 9.656946\n"
     ]
    }
   ],
   "source": [
    "# End time\n",
    "toc0 = time.clock()\n",
    "print(\"Total time: \" + str(toc0 - tic0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
